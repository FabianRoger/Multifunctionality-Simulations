---
title: "Untitled"
output: html_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

```

This script produces:

+ Figure S1

In this script we set up simulations with correlated function values as in van der Plas et al. (2016) "Jack-of-all-trades effects drive biodiversity–ecosystem multifunctionality relationships in European forests". Note that the implementation differs from the original script from van der Plas et al. as we build the simulations within our framework. 


```{r, "load packages"}
library(ggplot2)
library(Cairo)
library(grid)
library(cowplot)
library(dplyr)
library(tidyr)
library(corrplot)
library(magrittr)
library(gridExtra)

source("Multifunc_simulations_functions.R")
```

This script is largely identical to the script [Explanation_of_slope_pattern.Rmd](Explanation_of_slope_pattern.Rmd) but the function values are replaced by correlated function values genreated by `mvrnorm`.

set the average correlation with the `COR` argument. Note that not all correlations are mathematically possible, especially not all functions can be negatively correlated to each other. 

**alse note that the `distribution` parameter is irrelevant here, as the values will be replaced by correlated function values**

```{r, "funcmat"}
# set seed to replicate analysis:
set.seed(999)

# number of species
specnum <- 10

# number of functions
funcnum <- 9

# distribution from which to draw function values
distribution = "runif"

# choose pairwise correlation strength
COR <- 1

# make correlation matrix (strictly speaking a covariance matrix but for these simulations it does not matter)

Sigma <- matrix(COR, ncol = funcnum, nrow = funcnum)
diag(Sigma) <- 1

# create function matrix
FuncMat <- FunctionValue(specnum,funcnum, distribution, min = 0, max = 1)

# replace function values with correlated function values
FuncMat_long <- FuncMat %>% spread(Functions, Funcval)

FuncMat_long[,2:(funcnum+1)] <- mvrnorm(n = specnum, mu = rep(0, funcnum), Sigma = Sigma)

FuncMat <- FuncMat_long %>% 
  gather(Functions, Funcval, -Species) %>% 
  group_by(Functions) %>% 
  mutate(Funcval = Funcval + abs(min(Funcval)))
```

### Plot function values and function correlations
```{r, "corrplot"}

FuncMat_plot <- 
  FuncMat %>% 
  group_by(Functions) %>% 
  mutate(Funcval = Funcval / max(Funcval)) %>% 
  #mutate(Funcval = (Funcval - min(Funcval)) / (max(Funcval) - min(Funcval))) %>% 
  spread(Functions, Funcval) %>% 
  select(-Species)
  

FuncMat_plot %>% 
  mutate(av = rowMeans(.)) %>%
  as.matrix() %>% 
  set_rownames(unique(FuncMat$Species)) %>%
  corrplot( is.corr = F, tl.col = "black", cl.ratio = 0.2, 
           cl.length = 11, method="square", cl.lim = c(0,1))


FuncMat_plot %>% cor %>% 
  corrplot(type = "lower", tl.col = "black", cl.ratio = 0.2, 
           cl.length = 11, number.cex = 0.6, addCoef.col = "#323232", diag = F, method="ellipse")

```

```{r, "Avfunc"}
# code takes ~5 min to run for 15 species. Set to lower value for higher number of species! 

maxrep <- choose(specnum, floor(specnum/2))
#maxrep <- 10

# simulate plot x species matrix
SpecMat <- SpeciesMatrix(specnum = specnum, maxrep = maxrep)

# select method and additional parameters if appropriate by setting the `if` statement to `TRUE`
if (TRUE) {method = "av"}

if (FALSE) {method = "comp"
            CF = 3
            compfunc = c("F 1", "F 6")
            r = 0.25}


# Average function
AvFunc <- AverageFunction(SpecMat, FuncMat,
                          method = method, 
                          CF = CF, 
                          compfunc = compfunc,
                          r = r)
```

### Standardize function values

There are two main ways to standardize the function values:

+ between 0 and 1 with $x_{stand} = \frac{x - min(x)}{max(x) - min(x)}$

+ by the maximum with $x_{stand} = \frac{x}{max(x)}$

```{r, "standardize"}
# extract function names
func.names <- as.character( unique( FuncMat$Functions))

# standardize by maximum
 AvFunc[,func.names] <- apply(AvFunc[,func.names], 2, function(x) {x/max(x)})

 # alternative standardize between 0 and 1
#AvFunc[,func.names] <- apply(AvFunc[,func.names], 2, function(x) {(x - min(x)) / (max(x) - min(x))})
```

### Plot single function values
```{r, "single_func"}
AvFunc_long <- gather(AvFunc[, -c(1:specnum)], Function, FuncVal, -Richness) 

SingleFunc <- AvFunc_long %>%
  mutate(FuncVal = round(FuncVal,3)) %>% 
  group_by(Richness, Function, FuncVal) %>% 
  summarize(n = n()) %>% 
  ggplot(., aes(x=Richness, y=FuncVal, colour = n))+
  geom_point( size = 1, position = position_jitter(width = 0.1))+
  facet_wrap(~Function)+
  theme_bw(base_size=15)+
  stat_smooth(data = AvFunc_long, aes(x = Richness, y = FuncVal), method="lm", colour = "#de2d26") +
  xlab("\nSpecies richness") +
  ylab("Value of function\n") +
  theme(panel.grid = element_blank(), legend.position = "none")

SingleFunc

```

### Average approach for multifunctionality

+ Multifunctionality is calculated as the average value of the standardized single functions.

```{r, "multifunc_av"}

# add averaged multifunctional index
AvFunc$meanFunction <- rowMeans(AvFunc[,func.names])

# plot
AverageFunc <- 
  AvFunc %>%
  select(Richness, meanFunction) %>% 
  mutate(meanFunction = round(meanFunction,3)) %>% 
  group_by(Richness, meanFunction) %>% 
  summarize(n = n()) %>% 
  ggplot(., aes(x=Richness, y=meanFunction, colour = n))+
  geom_point(size = 2, position = position_jitter(width = 0.1))+
    theme_bw(base_size=15)+
    stat_smooth(data = AvFunc, aes(x = Richness, y = meanFunction), method="lm", colour = "#de2d26") +
    xlab("\nSpecies richness") +
    ylab("Average value of standardized functions\n")+
  theme(legend.position = "none")+
   # scale_y_continuous(limits = c(0.25,0.75))+
    scale_x_continuous(breaks = seq(1,15,2))

AverageFunc

```


```{r}

RES_func <- data.frame(thresholds = numeric(), 
                   Richness = numeric(), 
                   funcMaxed = numeric(), 
                   nFunc = numeric(), 
                   thresh = numeric())

# empty dataframe to store results
RES_slope <- data.frame(thresholds = numeric(), 
                   Estimate = numeric(), 
                   `Std. Error` = numeric(), 
                   `t value` = numeric(), 
                   `Pr(>|t|)` = numeric(), 
                   nfunc = numeric(),
                   func_comb = numeric())


#loop over chosen subsets of all function of varying size
for (i in c(ceiling(funcnum/2), funcnum)) { 
    
    # number of functions above threshold
    mixedThresh <- getFuncsMaxed(AvFunc, func.names[1:i], threshmin=0.05,
                                 threshmax=0.99, prepend=c("Richness"), maxN=1)
    
    RES_func <- rbind(RES_func, mixedThresh)
    
    # slopes  
    mixedLinearSlopes<-getCoefTab(funcMaxed ~ Richness, fun = lm, 
                                  data=mixedThresh, coefVar="Richness")
    
    colnames(mixedLinearSlopes) <- c("thresholds", "Estimate",
                                     "Std. Error", "t value", "Pr(>|t|)")
    
    temp <- mixedLinearSlopes %>% 
     # select(thresholds, Estimate) %>% 
      mutate(nfunc = i) %>% 
      mutate(func_comb = k)
    
    RES_slope <- rbind(RES_slope, temp)
  
  }

```

### Single-threshold approach for multifunctionality

+ Multifunctionality is calculated as the number of functions that are sustained above a pre-defined threshold - calculated as a percentage of the maximum observed function value across all plots.

```{r, "single_thresh"}


RES_func_p <- filter(RES_func, as.character(thresholds) %in% as.character(seq(0,1,0.1))) %>% 
  mutate(prct = paste(thresholds * 100, "%")) %>% 
  select(Richness, funcMaxed, prct, nFunc) 

singleThresh <- 
RES_func_p %>% 
  group_by(Richness, funcMaxed, prct, nFunc) %>% 
  summarise(n = n()) %>% 
  ggplot(., aes(x = Richness, y = funcMaxed, fill = as.factor(nFunc)))+
  geom_point(shape = 21, size = 2.5, colour = "black", stroke = 0.3, 
             position = position_dodge(width = 0.5), alpha = 0.5)+
  stat_smooth(data = RES_func_p, method = "lm", aes(colour = as.factor(nFunc)), se = F)+
  facet_wrap(~prct)+
  labs(x = "Species richness", y = "Number of functions ≥ threshold")+
  theme_bw(base_size=12)+
  scale_fill_brewer(guide = FALSE, palette = "Set1")+
  scale_colour_brewer(guide = FALSE, palette = "Set1")+
  scale_x_continuous(breaks = seq(0,10,2))+
  scale_y_continuous(breaks = c(0, 5, 9))+
  theme(legend.position = "none")


singleThresh
```

Note that if we set the correlation to 1, all species must perform all functions at the same level, so each function has the exact same average across species. This means that any given mixture can only provide all functions or no functions above any given threshold - which leads to the binary oucome above. Fitting a linear model to a binary variable will then produce large confidence intervals if the replication is low (as described in van der Plas et al. 2016).

### Plot with variable number of functions

```{r}

FUNC <- RES_slope %>% 
  mutate(CI_high = Estimate + 1.96*`Std. Error`,
         CI_low = Estimate - 1.96*`Std. Error`) %>%
ggplot(., aes(x=thresholds*100, y=Estimate), size = 0.5, alpha = 0.3)+
  geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = as.factor(nfunc)), colour = NA, alpha = 0.4)+
  geom_line( aes(colour = as.factor(nfunc)), lwd = 0.8) +
  ylab("Slope estimate") + xlab("Threshold (%)") +
  geom_abline(intercept=0, slope=0, lwd=0.5, linetype=2) + 
  theme_bw(base_size=15)+
  scale_fill_brewer(guide = FALSE, palette = "Set1")+
  scale_color_brewer(guide = guide_legend(title = paste("Number of functions", 
                                                        paste("(", specnum, " species)", 
                                                              sep = ""), sep = "\n"),
                                          nrow=2,byrow=TRUE),
                     palette = "Set1")+
  theme_classic()+
  theme(legend.position = c(0.8,0.8))
  scale_y_continuous(limits = c(-0.45, 0.45)) 
  
FUNC
```


### Figure S1

```{r}
library(grid)


# create an apporpriate viewport.  Modify the dimensions and coordinates as needed
vp.Middle <- viewport(height=unit(1, "npc"), width=unit(1/3, "npc"), 
                           just=c("left","top"), 
                           y=1, x=1/3)

vp.Right <- viewport(height=unit(1, "npc"), width=unit(1/3, "npc"), 
                           just=c("left","top"), 
                           y=1, x=2/3)


cairo_pdf(filename = "Figure_S1.pdf", width = 12, height = 4, pointsize = 10)
# plot your base graphics 
par(mfrow=c(1,3))

# First base plot
FuncMat_plot %>% 
  mutate(av = rowMeans(.)) %>%
  arrange(-`F 1`) %>% 
  as.matrix() %>% 
  set_rownames(unique(FuncMat$Species)) %>%
  corrplot( is.corr = F, tl.col = "black", cl.ratio = 0.2, 
           cl.length = 11, method="square", cl.lim = c(0,1),
           tl.cex = 1.5, cl.cex = 1.2)


# plot the ggplot using the print command
print(singleThresh, vp=vp.Middle)


# plot the ggplot using the print command
print(FUNC, vp=vp.Right)


```

